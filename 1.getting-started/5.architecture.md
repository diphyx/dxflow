---
title: Architecture
description: Discover dxflow's flexible architecture patterns and deployment models for distributed computing across any infrastructure
navigation:
    icon: i-hugeicons:layers-01
---

dxflow is designed as a lightweight, distributed computing platform that enables seamless orchestration of data and compute workflows across heterogeneous computing environments. 

::callout{type="info"}
**Architecture Philosophy**: dxflow follows a "compute-first" design where the engine runs close to your workloads, eliminating data movement bottlenecks and reducing operational complexity.
::

## Deployment Patterns

dxflow supports two primary deployment patterns, each optimized for different use cases and organizational needs:

::card-group
  ::card{title="Node-Embedded" icon="i-hugeicons:distributed-node"}
  **Direct Integration**
  
  Every compute node runs its own dxflow engine with no additional control layer between infrastructure and schedulers.
  
  **Best For:**
  - High-performance computing clusters
  - Edge computing deployments  
  - Minimal operational overhead scenarios
  - Maximum performance requirements
  ::

  ::card{title="Federated Master" icon="i-hugeicons:hierarchy"}
  **Centralized Orchestration**
  
  A master dxflow instance coordinates a fleet of engine agents across multiple nodes and environments.
  
  **Best For:**
  - Multi-cloud deployments
  - Complex workflow orchestration
  - Centralized monitoring and control
  - Enterprise governance requirements
  ::
::

### Unified Interface Components

Regardless of deployment pattern, every dxflow engine provides a consistent set of interfaces:

::tabs
  ::tab-item{label="REST APIs" icon="i-hugeicons:api"}
  - **Programmatic Access**: Full automation and integration capabilities
  - **Language Agnostic**: Compatible with any programming language
  - **Real-time Communication**: WebSocket support for live updates
  - **OpenAPI Specification**: Complete documentation and client generation
  ::

  ::tab-item{label="Command Line Interface" icon="i-hugeicons:terminal"}
  - **Local & Remote**: Execute commands locally or against remote engines
  - **Scriptable Operations**: Perfect for CI/CD and automation pipelines  
  - **Interactive Mode**: Rich terminal experience with progress indicators
  - **Cross-Platform**: Consistent experience across Linux, macOS, and Windows
  ::

  ::tab-item{label="Web Console" icon="i-hugeicons:browser"}
  - **Visual Management**: Point-and-click workflow creation and monitoring
  - **Real-time Dashboards**: Live system metrics and resource utilization
  - **Mobile Responsive**: Access from any device, anywhere
  - **Collaborative Features**: Multi-user access with role-based permissions
  ::

  ::tab-item{label="Proxy Services" icon="i-hugeicons:network"}
  - **Secure Tunneling**: Access internal services through authenticated proxies
  - **Load Balancing**: Distribute traffic across multiple backend services
  - **Protocol Support**: HTTP/HTTPS, TCP, and WebSocket proxying
  - **Dynamic Configuration**: Runtime proxy setup without restarts
  ::
::

::alert{type="success"}
**Performance**: The most common and recommended deployment pattern is **Node-Embedded**, offering the lowest latency and highest throughput by eliminating network hops between the engine and compute resources.
::

## Node-Embedded Deployment

![dxflow Architecture](/assets/architecture_light.png)
The Node-Embedded pattern places a dxflow engine directly on every compute target—whether it's an EC2 spot instance, an on-premises Slurm node, or a Docker container on a lab workstation.

### Key Characteristics

::card-group
  ::card{title="Ultra-Fast Bootstrap" icon="i-hugeicons:speed"}
  - **≤ 2 Second Startup**: Engine boots and registers instantly
  - **Automatic Registration**: RSA key-pair authentication setup
  - **Zero Configuration**: Works out-of-the-box with sensible defaults
  ::

  ::card{title="Uniform Endpoints" icon="i-hugeicons:interface"}
  - **Consistent APIs**: Same interface across all node types
  - **Standard Ports**: Predictable networking and discovery
  - **Auto-Discovery**: Engines announce themselves to the fleet
  ::
::

### Access Points

Each engine immediately exposes multiple access methods:
#### [API](/docs/api)
```url
http://localhost:<port>/api — REST & gRPC

```
#### [CLI](/docs/cli)
```
```bash
dxflow <cmd> — local CLI passthrough
```
#### [Console](/console)
```url
http://localhost:<port>/console — web console

```
and console access via a web browser at `http://localhost:<port>/console`.

Because the runtime is embedded at the node level, dxflow cohabits peacefully with any resource scheduler already present:

- Slurm / PBS / LSF: the prolog script starts dxflow when a job allocation begins.
- Kubernetes / Nomad: deploy the agent as a DaemonSet or side-car.
- Docker Compose / Podman: include the dxflow container in the same docker-compose.yml.
- Spark / Ray / AWS Batch: each executor or EC2 instance bundles the agent via user-data.

This design mirrors the side-car model popularised by Dapr: place a lightweight process next to every workload to provide cross-cutting capabilities (for Dapr: service discovery, pub-sub, state; for dxflow: data staging, secure shell, log streaming, UI). The result is a flat fleet of self-sufficient nodes—no single point of failure, and no extra tier to manage.

### Federated Master Deployment
In the federated master deployment, a single dxflow instance acts as a control plane for the entire fleet of compute nodes. This master instance orchestrates the dxflow agents running on each node or container, providing a centralized interface for managing and monitoring the computational tasks. This setup is particularly useful for larger deployments where centralized management and monitoring are required.
